import random
import time
from services.authen import LinkedInAuthenticator
from scraper.company_scraper import LinkedInCompanyScraper
from scraper.profile_scraper import LinkedInProfileScraper
from services.driver_management import ChromeDriverManager
from scraper.data_manager import DataManager
from typing import List, Dict
from scraper.my_network_scraper import LinkedInMyNetworkScraper
from services.human_behavior import HumanBehaviorSimulator 
from repositories.url_repository import UrlRepository
from repositories.profile_repository import ProfileRepository
class LinkedInScraperManager:
    """Class ch√≠nh qu·∫£n l√Ω to√†n b·ªô qu√° tr√¨nh scraping"""
    
    def __init__(self, profile_name: str = "linkedin_profile", id: str = None):
        self.driver_manager = ChromeDriverManager(id,profile_name)
        self.driver = None
        self.authenticator = None
        self.company_scraper = None
        self.profile_scraper = None
        self.my_connect_scraper = None
        self.stop = False
        self.id = id
     
    def set_stop(self):
        """Thi·∫øt l·∫≠p tr·∫°ng th√°i d·ª´ng"""
        self.stop = True
        if self.my_connect_scraper:
            self.my_connect_scraper.stop = True
        print(f"üî¥ Tr·∫°ng th√°i d·ª´ng ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p: {self.stop}") 

    def is_stopped(self) -> bool:
        """Ki·ªÉm tra tr·∫°ng th√°i d·ª´ng"""
        return self.stop
        
    def initialize_driver(self) -> bool:
        """Kh·ªüi t·∫°o driver v√† c√°c scraper"""
        self.driver = self.driver_manager.create_edge_driver_with_session()
        if not self.driver:
            return False
        
        self.authenticator = LinkedInAuthenticator(self.driver)
        self.company_scraper = LinkedInCompanyScraper(self.driver)
        self.profile_scraper = LinkedInProfileScraper(self.driver)
        self.my_connect_scraper = LinkedInMyNetworkScraper(self.driver)
        return True
    
    def login(self, email: str, password: str) -> bool:
        """ƒêƒÉng nh·∫≠p LinkedIn"""
        if not self.authenticator:
            print("‚ùå Driver ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
            return False
        return self.authenticator.smart_login(email, password)
    
    def scrape_company_profiles(self, company_url: str) -> List[Dict]:
        """Scrape t·∫•t c·∫£ profiles t·ª´ m·ªôt c√¥ng ty"""
        if not self.company_scraper:
            print("‚ùå Company scraper ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
            return []
        
        # L·∫•y danh s√°ch URL
        profile_urls = self.company_scraper.expand_and_collect_all_urls(company_url)
        if not profile_urls:
            print("‚ùå Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c URL profile n√†o")
            return []
        
        # L∆∞u danh s√°ch URL
        DataManager.save_profiles_to_file(profile_urls, "collected_profile_urls.json")
        
        # L·∫•y th√¥ng tin chi ti·∫øt
        detailed_profiles = self.profile_scraper.get_all_profile_details(profile_urls)
        
        if detailed_profiles:
            DataManager.save_profiles_to_file(detailed_profiles, "linkedin_detailed_profiles_final.json")
        
        return detailed_profiles
    
    def scrape_my_connect_profiles(self, bot_id: str) -> List[Dict]:
        if not self.my_connect_scraper:
            print("‚ùå My Connect scraper ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
            return []
        url_repo = UrlRepository()
        profile_repo = ProfileRepository()

        print("self.stop", self.stop)
        
        profile_urls = self.my_connect_scraper.expand_and_collect_all_urls(bot_id=bot_id, stop=self.stop)
        
        
        return profile_urls
        # for log in profile_urls:
        #     yield log
        #     print(log.message)

        # print(f"üìä ƒê√£ thu th·∫≠p {profile_urls} profile URLs t·ª´ My Network")
        # if not profile_urls:
        #     print("‚ùå Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c URL profile n√†o t·ª´ My Network")
        #     return []
        url_repository = UrlRepository()
        
        urls_to_crawl = url_repository.get_urls_by_bot_id(1)
        
        detailed_profiles = self.profile_scraper.get_all_profile_details(urls_to_crawl, url_repo, profile_repo)
       
        return detailed_profiles
    
    def logout(self) -> bool:
        """ƒêƒÉng xu·∫•t LinkedIn"""
        if not self.authenticator:
            return False
        return self.authenticator.logout()
    
    def cleanup(self):
        """ƒê√≥ng driver"""
        if self.driver:
            print("üîê ƒêang ƒë√≥ng tr√¨nh duy·ªát...")
            self.driver.quit()
            self.driver = None
    def search_people(self, name: str):
        """
        T√¨m ki·∫øm ng∆∞·ªùi v·ªõi t√™n ƒë∆∞·ª£c cung c·∫•p v√† thu th·∫≠p profile URLs qua nhi·ªÅu trang
        """
        print(f"üîç B·∫Øt ƒë·∫ßu t√¨m ki·∫øm: {name}")
        
        # B∆∞·ªõc 1: Nh·∫≠p t√™n ng∆∞·ªùi c·∫ßn t√¨m
        self.search.input_people_name(name)
        HumanBehaviorSimulator.random_wait_after_action()
        
        # B∆∞·ªõc 2: Click tab "People/Ng∆∞·ªùi"
        self.search.click_people_tab()
        HumanBehaviorSimulator.random_wait_after_action()
        
        # Delay v√† di chuy·ªÉn chu·ªôt t·ª± nhi√™n
        print("üìç M√¥ ph·ªèng h√†nh vi ng∆∞·ªùi d√πng...")
        HumanBehaviorSimulator.random_delay(2, 4)
        
        # Di chuy·ªÉn chu·ªôt random tr√™n trang
        self._simulate_natural_mouse_movement()
        
        all_profile_urls = []
        
        # B∆∞·ªõc 3: Thu th·∫≠p d·ªØ li·ªáu qua 10 trang
        for page in range(10):
            print(f"\nüìÑ ƒêang x·ª≠ l√Ω trang {page + 1}/10...")
            
            # Scroll xu·ªëng ƒë·ªÉ load h·∫øt n·ªôi dung
            print("‚¨áÔ∏è ƒêang scroll xu·ªëng trang...")
            self._scroll_page_naturally()
            
            # Thu th·∫≠p profile URLs t·ª´ trang hi·ªán t·∫°i
            print("üéØ Thu th·∫≠p profile URLs...")
            page_profiles = self.search.scrapper_a_tag()
            
            if page_profiles:
                all_profile_urls.extend(page_profiles)
                print(f"‚úÖ Trang {page + 1}: Thu th·∫≠p ƒë∆∞·ª£c {len(page_profiles)} profiles")
            else:
                print(f"‚ö†Ô∏è Trang {page + 1}: Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c profile n√†o")
            
            # N·∫øu ch∆∞a ph·∫£i trang cu·ªëi, click Next
            if page < 9:  # Ch·ªâ click Next 9 l·∫ßn (trang 1->2, 2->3, ..., 9->10)
                print("‚û°Ô∏è Chuy·ªÉn sang trang ti·∫øp theo...")
                
                # Delay tr∆∞·ªõc khi click Next
                HumanBehaviorSimulator.random_delay(1.5, 3)
                
                # Di chuy·ªÉn chu·ªôt tr∆∞·ªõc khi click
                self._move_mouse_before_click()
                
                # Click n√∫t Next
                success = self.search.click_next_button()
                if not success:
                    print(f"‚ùå Kh√¥ng th·ªÉ chuy·ªÉn sang trang {page + 2}. D·ª´ng thu th·∫≠p.")
                    break
                
                # Delay sau khi click Next
                HumanBehaviorSimulator.random_wait_after_action()
                HumanBehaviorSimulator.random_delay(2, 4)
        
        # B∆∞·ªõc 4: T·ªïng k·∫øt k·∫øt qu·∫£
        print(f"\nüéâ Ho√†n th√†nh thu th·∫≠p!")
        print(f"üìä T·ªïng s·ªë profile URLs thu th·∫≠p ƒë∆∞·ª£c: {len(all_profile_urls)}")
        
        # Lo·∫°i b·ªè duplicate URLs
        unique_profiles = self._remove_duplicate_profiles(all_profile_urls)
        print(f"üîÑ Sau khi lo·∫°i b·ªè duplicate: {len(unique_profiles)} profiles unique")
        
        # L∆∞u k·∫øt qu·∫£ v√†o file (tu·ª≥ ch·ªçn)
        if unique_profiles:
            DataManager.save_profiles_to_file(unique_profiles, f"search_results_{name.replace(' ', '_')}.json")
            print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file search_results_{name.replace(' ', '_')}.json")
        
        return unique_profiles


    def _remove_duplicate_profiles(self, profiles):
        """Lo·∫°i b·ªè profile URLs tr√πng l·∫∑p"""
        seen_urls = set()
        unique_profiles = []
        
        for profile in profiles:
            url = profile.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_profiles.append(profile)
        
        return unique_profiles
    def _simulate_natural_mouse_movement(self):
            """M√¥ ph·ªèng di chuy·ªÉn chu·ªôt t·ª± nhi√™n tr√™n trang"""
            try:
                from selenium.webdriver.common.action_chains import ActionChains
                
                # L·∫•y k√≠ch th∆∞·ªõc window
                window_size = self.driver.get_window_size()
                width = window_size['width']
                height = window_size['height']
                
                # Di chuy·ªÉn chu·ªôt ƒë·∫øn 3-5 v·ªã tr√≠ ng·∫´u nhi√™n
                actions = ActionChains(self.driver)
                
                for _ in range(random.randint(3, 5)):
                    x = random.randint(100, width - 100)
                    y = random.randint(100, height - 100)
                    
                    actions.move_by_offset(x - width//2, y - height//2)
                    actions.perform()
                    
                    time.sleep(random.uniform(0.3, 0.8))
                    
                    # Reset ƒë·ªÉ tr√°nh l·ªói offset t√≠ch l≈©y
                    actions = ActionChains(self.driver)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ m√¥ ph·ªèng di chuy·ªÉn chu·ªôt: {e}")

    def _scroll_page_naturally(self):
        """Scroll trang m·ªôt c√°ch t·ª± nhi√™n"""
        # Scroll xu·ªëng t·ª´ng ƒëo·∫°n nh·ªè
        for _ in range(random.randint(3, 6)):
            HumanBehaviorSimulator.human_scroll(self.driver)
            time.sleep(random.uniform(0.5, 1.2))
        
        # Scroll v·ªÅ ƒë·∫ßu trang m·ªôt ch√∫t
        self.driver.execute_script("window.scrollBy(0, -200);")
        time.sleep(random.uniform(0.3, 0.7))

    def _move_mouse_before_click(self):
        """Di chuy·ªÉn chu·ªôt tr∆∞·ªõc khi click ƒë·ªÉ t·ª± nhi√™n h∆°n"""
        try:
            from selenium.webdriver.common.action_chains import ActionChains
            
            # Di chuy·ªÉn chu·ªôt m·ªôt ch√∫t
            actions = ActionChains(self.driver)
            actions.move_by_offset(random.randint(-50, 50), random.randint(-30, 30))
            actions.perform()
            
            time.sleep(random.uniform(0.2, 0.5))
            
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ di chuy·ªÉn chu·ªôt: {e}")
    