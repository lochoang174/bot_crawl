import time
from scraper.scraper_management import LinkedInScraperManager
from services.driver_management import ChromeDriverManager
from services.edit_profile import LinkedInProfileViewer
from repositories.url_repository import UrlRepository
from repositories.profile_repository import ProfileRepository

def test_multiple_accounts():
    """Test vá»›i nhiá»u tÃ i khoáº£n"""
    ACCOUNT_LIST = [ 
        {
            "LINKEDIN_EMAIL": "ClarieBarbourclf38421z@cwhats.us",
            "LINKEDIN_PASSWORD": "Truong3979"
        }
    ]
    
    COMPANY_URL = "https://www.linkedin.com/company/tiger-tribe-heineken/people/"
    
    for account in ACCOUNT_LIST:
        email = account["LINKEDIN_EMAIL"]
        password = account["LINKEDIN_PASSWORD"]
        
        scraper = LinkedInScraperManager()
        
        try:
            print(f"\nğŸ” ÄÄƒng nháº­p vá»›i tÃ i khoáº£n: {email}")
            
            if not scraper.initialize_driver():
                print(f"âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver cho {email}")
                continue
            
            if scraper.login(email, password):
                print("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng! Truy cáº­p cÃ´ng ty...")
                scraper.driver.get(COMPANY_URL)
                time.sleep(3)
                company =scraper.company_scraper
                company.expand_and_collect_all_urls("https://www.linkedin.com/company/itviec/people/")
                time.sleep(5)  # Nghá»‰ giá»¯a cÃ¡c tÃ i khoáº£n

                scraper.logout()
                print("ğŸ” ÄÃ£ Ä‘Äƒng xuáº¥t.")
            else:
                print(f"âŒ KhÃ´ng thá»ƒ Ä‘Äƒng nháº­p vá»›i {email}")
                
        except Exception as e:
            print(f"âŒ Lá»—i khi thá»±c hiá»‡n vá»›i {email}: {e}")
        finally:
            scraper.cleanup()
            time.sleep(5)  # Nghá»‰ giá»¯a cÃ¡c tÃ i khoáº£n


def main():
    """HÃ m main Ä‘á»ƒ cháº¡y scraper"""
    ACCOUNT_LIST = [
     
        {
            "LINKEDIN_EMAIL": "EmmyWhiteheadvaq35799d@bizdir.us",
            "LINKEDIN_PASSWORD": "lamtruongphu2003"
        }
    ]
    
    COMPANY_URL = "https://www.linkedin.com/company/tiger-tribe-heineken/people/"
    
    # Sá»­ dá»¥ng tÃ i khoáº£n Ä‘áº§u tiÃªn
    account = ACCOUNT_LIST[0]
    scraper = LinkedInScraperManager()
    
    try:
        print("ğŸš€ Khá»Ÿi táº¡o LinkedIn Scraper...")
        
        if not scraper.initialize_driver():
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver")
            return
        
        if not scraper.login(account["LINKEDIN_EMAIL"], account["LINKEDIN_PASSWORD"]):
            print("âŒ ÄÄƒng nháº­p tháº¥t báº¡i")
            return
        
        print("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng! Báº¯t Ä‘áº§u scraping...")
        scraper.search_people("anh")
        # Scrape company profiles
        # detailed_profiles = scraper.scrape_company_profiles(COMPANY_URL)
        
        # if detailed_profiles:
        #     print(f"\nâœ… HoÃ n táº¥t! Thu tháº­p Ä‘Æ°á»£c {len(detailed_profiles)} profiles chi tiáº¿t")
        # else:
        #     print("âŒ KhÃ´ng thu tháº­p Ä‘Æ°á»£c thÃ´ng tin nÃ o")
        
        # print("\nTrÃ¬nh duyá»‡t sáº½ Ä‘Æ°á»£c giá»¯ má»Ÿ Ä‘á»ƒ báº¡n kiá»ƒm tra...")
        # print("Nháº¥n Ctrl+C trong terminal Ä‘á»ƒ thoÃ¡t vÃ  Ä‘Ã³ng trÃ¬nh duyá»‡t.")
        
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh theo yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng.")
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
        import traceback
        traceback.print_exc()
    finally:
        scraper.cleanup()

def my_connect_scraper():
    """HÃ m main Ä‘á»ƒ cháº¡y scraper"""
    ACCOUNT_LIST = [
        {
            "LINKEDIN_EMAIL": "heidivitaleqxo77592s@teom.us",
            "LINKEDIN_PASSWORD": "Truong3979"
        },
    ]
    
    # Array of company names
    company_names = ["Vietnam", "VNG"]
   
    # Sá»­ dá»¥ng tÃ i khoáº£n Ä‘áº§u tiÃªn
    account = ACCOUNT_LIST[0]
    scraper = LinkedInScraperManager()    
    try:
        print("ğŸš€ Khá»Ÿi táº¡o LinkedIn Scraper...")
        
        if not scraper.initialize_driver():
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o driver")
            return
        
        if not scraper.login(account["LINKEDIN_EMAIL"], account["LINKEDIN_PASSWORD"]):
            print("âŒ ÄÄƒng nháº­p tháº¥t báº¡i")
            return
        
        print("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng! Báº¯t Ä‘áº§u scraping...")
        
        # scraper.driver.get("https://www.linkedin.com/mynetwork")
        # time.sleep(3)
        # edit_profile = LinkedInProfileViewer(scraper.driver, company_name="hello")
        # edit_profile.view_and_edit_profile()

        
        for index, company_name in enumerate(company_names):  # Iterate through the company names with index
            print(f"\nğŸ¢ Äang xá»­ lÃ½ cÃ´ng ty: {company_name}")
            edit_profile = LinkedInProfileViewer(scraper.driver, company_name=company_name)
            
            while True:  # Recursive loop
                # Scrape my connect profiles
                detailed_profiles = scraper.scrape_my_connect_profiles()
                
                if detailed_profiles:
                    print(f"âœ… HoÃ n táº¥t! Thu tháº­p Ä‘Æ°á»£c {len(list(detailed_profiles))} profiles chi tiáº¿t tá»« My Network")
                else:
                    print("âŒ KhÃ´ng thu tháº­p Ä‘Æ°á»£c thÃ´ng tin nÃ o tá»« My Network")
                
                # Click the close modal button and edit profile
                print("ğŸ”„ Äang Ä‘Ã³ng modal vÃ  chá»‰nh sá»­a profile...")
                edit_profile.view_and_edit_profile()
                
                # Add a delay to avoid overwhelming the server
                time.sleep(5)
                
                # Check if this is the last company in the array
                if index == len(company_names) - 1:
                    print(f"ğŸ¢ CÃ´ng ty cuá»‘i cÃ¹ng: {company_name}. Tiáº¿p tá»¥c thu tháº­p profiles...")
                    continue  # Continue scraping profiles for the last company
                
                print(f"ğŸ¢ ÄÃ£ hoÃ n thÃ nh xá»­ lÃ½ cÃ´ng ty: {company_name}")
                break 
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh theo yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng.")
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
        import traceback
        traceback.print_exc()
    finally:
        scraper.cleanup()
        
def test_scraper():
    url_repo = UrlRepository()
    profile_repo = ProfileRepository()

    # Update status to 'pending' for URLs not in 'profile_details'
    url_repo.update_status_to_pending_if_not_in_profiles(profile_repo)
        
        
        
if __name__ == "__main__":
    # driver = ChromeDriverManager().create_undetected_driver_with_session()
    # driver.get("https://bot.sannysoft.com")
    # my_connect_scraper()
    # test_scraper()
    # test_multiple_accounts()