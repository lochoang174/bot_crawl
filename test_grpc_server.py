import time
import grpc
from concurrent import futures
import sys
import os
import threading
import queue  # Import a thread-safe queue
from scraper.scraper_management import LinkedInScraperManager
from services.edit_profile import LinkedInProfileViewer
# ----------------------------------------------------

sys.path.append(os.path.join(os.path.dirname(__file__), 'proto'))
from proto import bot_pb2
from proto import bot_pb2_grpc

# Tr·∫°ng th√°i c√°c bot ƒëang ch·∫°y
# Gi·ªù ƒë√¢y s·∫Ω l∆∞u tr·ªØ c·∫£ scraper, queue v√† thread
# ƒê√£ th√™m tr·∫°ng th√°i c·ªßa bot: RUNNING, STOPPED, PENDING
active_bots = {}

# H√†m n√†y s·∫Ω ƒë∆∞·ª£c ch·∫°y trong m·ªôt thread ri√™ng
def _run_scraper_task(bot_id: str, log_queue: queue.Queue, scraper: LinkedInScraperManager, account: dict, company_names: list):
    """
    H√†m th·ª±c hi·ªán c√¥ng vi·ªác scrape d·ªØ li·ªáu.
    N√≥ s·∫Ω ch·∫°y trong m·ªôt lu·ªìng ri√™ng ƒë·ªÉ kh√¥ng ch·∫∑n server gRPC.
    """
    try:
        log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="üöÄ Initializing LinkedIn Scraper..."))

        if not scraper.driver: # Ch·ªâ initialize driver n·∫øu ch∆∞a c√≥
            if not scraper.initialize_driver():
                log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="‚ùå Driver initialization failed."))
                return

        # Ki·ªÉm tra xem ƒë√£ login ch∆∞a, n·∫øu c√≥ th·ªÉ th√¨ b·ªè qua login l·∫°i
        # (ƒê√¢y l√† m·ªôt ƒëi·ªÉm b·∫°n c·∫ßn c·∫£i thi·ªán trong scraper th·ª±c t·∫ø c·ªßa m√¨nh)
        log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="Attempting login..."))
        if not scraper.login(account["LINKEDIN_EMAIL"], account["LINKEDIN_PASSWORD"]):
            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="‚ùå Login failed."))
            scraper.cleanup() # Cleanup n·∫øu login th·∫•t b·∫°i
            return
        log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="‚úÖ Login successful! Starting scraping..."))

        for index, company_name in enumerate(company_names):
            # if scraper.is_stopped():  # KI·ªÇM TRA C·ªú D·ª™NG TR∆Ø·ªöC M·ªñI V√íNG L·∫∂P L·ªöN
            #     log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"üõë Scraping stopped by command for company: {company_name}."))
            #     break
            print(f"\n[{bot_id}] üè¢ Processing company: {company_name} (#{index + 1}/{len(company_names)})")
                
            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"\nüè¢ Processing company: {company_name}"))
            edit_profile = LinkedInProfileViewer(scraper.driver, company_name=company_name)
            
            # V√≤ng l·∫∑p b√™n trong ƒë·ªÉ x·ª≠ l√Ω ƒë·ªá quy (ho·∫∑c cho ƒë·∫øn khi kh√¥ng c√≤n profile)
            # Gi·∫£ ƒë·ªãnh ƒë√¢y l√† v√≤ng l·∫∑p l·∫•y nhi·ªÅu trang profile
            while not scraper.is_stopped(): # Lu√¥n ki·ªÉm tra c·ªù d·ª´ng
                detailed_profiles = scraper.scrape_my_connect_profiles(bot_id=bot_id)
                
                if detailed_profiles:
                    log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"‚úÖ Collected {len(list(detailed_profiles))} profiles from My Network"))
                else:
                    log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="‚ùå No more profiles to collect for this company."))
                    break # Tho√°t v√≤ng l·∫∑p n·ªôi b·ªô n·∫øu kh√¥ng c√≤n profile
                
                log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="üîÑ Closing modal and editing profile..."))
                edit_profile.view_and_edit_profile()
                
                time.sleep(5) # Kho·∫£ng d·ª´ng gi·ªØa c√°c l·∫ßn scrape
            
            if scraper.is_stopped(): # Tho√°t v√≤ng l·∫∑p ngo√†i n·∫øu ƒë√£ nh·∫≠n l·ªánh d·ª´ng
                break

        if not scraper.is_stopped(): # Ch·ªâ b√°o ho√†n th√†nh n·∫øu kh√¥ng b·ªã d·ª´ng gi·ªØa ch·ª´ng
            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="‚úÖ All scraping tasks completed for this session."))

    except Exception as e:
        import traceback
        error_message = f"‚ùå Unhandled error in scraper thread: {e}\n{traceback.format_exc()}"
        log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=error_message))
    finally:
        # Quan tr·ªçng: Kh√¥ng cleanup ngay l·∫≠p t·ª©c ·ªü ƒë√¢y. 
        # Cleanup s·∫Ω ƒë∆∞·ª£c g·ªçi khi bot b·ªã STOP ho·∫∑c khi server t·∫Øt
        # log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message="Scraper task finished.")) 
        print(f"[{bot_id}] Scraper task thread ended (driver might still be active).")
        scraper.cleanup()
        # ƒê√°nh d·∫•u bot l√† ƒë√£ d·ª´ng trong active_bots ƒë·ªÉ bi·∫øt tr·∫°ng th√°i
        if bot_id in active_bots:
            active_bots[bot_id]["status"] = "STOPPED" # Ho·∫∑c "COMPLETED" n·∫øu n√≥ ho√†n th√†nh xong

class BotServiceServicer(bot_pb2_grpc.BotServiceServicer):
    def StreamBotCrawlUrl(self, request_iterator, context):
        log_queue = queue.Queue()
        bot_id = None 

        def command_handler():
            nonlocal bot_id
            try:
                for command in request_iterator:
                    bot_id = command.bot_id
                    cmd_type = command.type
                    print(f"üì• Received command: {bot_pb2.BotCommand.CommandType.Name(cmd_type)} for bot_id={bot_id}")

                    if cmd_type == bot_pb2.BotCommand.START:
                        if bot_id in active_bots and active_bots[bot_id]["status"] == "RUNNING":
                            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"‚ö†Ô∏è Bot {bot_id} is already running."))
                            continue
                        
                        scraper = None
                        if bot_id in active_bots and active_bots[bot_id]["status"] == "STOPPED":
                            # Bot ƒë√£ t·ªìn t·∫°i v√† ƒë√£ d·ª´ng, c√≥ th·ªÉ kh·ªüi ƒë·ªông l·∫°i
                            scraper = active_bots[bot_id]["scraper"]
                            # Reset stop event ƒë·ªÉ cho ph√©p n√≥ ch·∫°y l·∫°i
                            scraper.cleanup() 
                            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"üîÑ Resuming bot {bot_id}..."))
                        else:
                            # Bot m·ªõi ho√†n to√†n
                            scraper = LinkedInScraperManager(id=bot_id)
                            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"‚ú® Starting new bot {bot_id}..."))

                        account = {
                            "LINKEDIN_EMAIL": "edwardwilson3512a47@gualues.com",
                            "LINKEDIN_PASSWORD": "Truong3979"
                        }
                        company_names = ["Vietnam", "VNG", "FPT"] # Th√™m 1 c√¥ng ty ƒë·ªÉ th·∫•y qu√° tr√¨nh
                        
                        worker_thread = threading.Thread(
                            target=_run_scraper_task,
                            args=(bot_id, log_queue, scraper, account, company_names)
                        )
                        active_bots[bot_id] = {"scraper": scraper, "thread": worker_thread, "status": "RUNNING"}
                        worker_thread.start()

                    elif cmd_type == bot_pb2.BotCommand.STOP:
                        if bot_id in active_bots and active_bots[bot_id]["status"] == "RUNNING":
                            scraper = active_bots[bot_id]["scraper"]
                            scraper.set_stop()  # G·ª≠i t√≠n hi·ªáu d·ª´ng
                            active_bots[bot_id]["status"] = "STOPPED" # C·∫≠p nh·∫≠t tr·∫°ng th√°i
                            print(f"üõë Stop signal sent to bot {bot_id}. Status set to STOPPED.")
                            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"üõë Stop command received. Bot will stop shortly."))
                            # KH√îNG X√ìA bot_id kh·ªèi active_bots ƒë·ªÉ c√≥ th·ªÉ kh·ªüi ƒë·ªông l·∫°i
                            # KH√îNG cleanup ·ªü ƒë√¢y, vi·ªác cleanup s·∫Ω do h√†m b√™n trong _run_scraper_task x·ª≠ l√Ω khi n√≥ k·∫øt th√∫c ho·∫∑c khi client ng·∫Øt k·∫øt n·ªëi
                        elif bot_id in active_bots and active_bots[bot_id]["status"] == "STOPPED":
                             log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"‚ö†Ô∏è Bot {bot_id} is already stopped."))
                        else:
                            log_queue.put(bot_pb2.BotLog(bot_id=bot_id, message=f"‚ö†Ô∏è No running bot found to stop for bot_id={bot_id}."))
            
            except grpc.RpcError as e:
                # Client ng·∫Øt k·∫øt n·ªëi
                print(f"Client disconnected for bot_id={bot_id if bot_id else 'unknown'}. Error: {e}")
                if bot_id and bot_id in active_bots and active_bots[bot_id]["status"] == "RUNNING":
                    # N·∫øu client ng·∫Øt k·∫øt n·ªëi khi bot ƒëang ch·∫°y, h√£y ra l·ªánh d·ª´ng bot ƒë√≥
                    print(f"Forcing stop for bot {bot_id} due to client disconnect.")
                    print(" Stopping scraper:" + active_bots[bot_id]["scraper"])
                    active_bots[bot_id]["scraper"].set_stop()
                    active_bots[bot_id]["status"] = "STOPPED"
                    # C√≥ th·ªÉ c√¢n nh·∫Øc g·ªçi cleanup ·ªü ƒë√¢y n·∫øu mu·ªën gi·∫£i ph√≥ng t√†i nguy√™n ngay l·∫≠p t·ª©c
                    # active_bots[bot_id]["scraper"].cleanup() 
                log_queue.put(bot_pb2.BotLog(bot_id=bot_id if bot_id else "unknown", message=f"Client disconnected. Bot will stop if running."))

            finally:
                # ƒê·∫∑t m·ªôt tin nh·∫Øn ƒë·∫∑c bi·ªát v√†o queue ƒë·ªÉ b√°o hi·ªáu command_handler ƒë√£ k·∫øt th√∫c
                # ƒêi·ªÅu n√†y gi√∫p StreamBotCrawlUrl bi·∫øt khi n√†o n√™n d·ª´ng vi·ªác g·ª≠i log
                log_queue.put(None)

        command_thread = threading.Thread(target=command_handler)
        command_thread.start()

        # V√≤ng l·∫∑p ch√≠nh c·ªßa lu·ªìng gRPC: ch·ªâ l·∫•y log t·ª´ queue v√† g·ª≠i cho client
        while True:
            try:
                # Ch·ªù log t·ª´ worker thread ho·∫∑c command_handler
                log = log_queue.get(timeout=1) 
                
                # N·∫øu nh·∫≠n ƒë∆∞·ª£c t√≠n hi·ªáu k·∫øt th√∫c t·ª´ command_handler (t·ª©c client ƒë√£ ng·∫Øt k·∫øt n·ªëi)
                if log is None:
                    print("Command handler finished (client disconnected). Closing log stream.")
                    break # Tho√°t v√≤ng l·∫∑p g·ª≠i log
                
                yield log

            except queue.Empty:
                # N·∫øu queue r·ªóng, ki·ªÉm tra xem client c√≤n k·∫øt n·ªëi kh√¥ng
                if not context.is_active():
                    print("Client context is inactive. Stopping log stream.")
                    # Khi client ng·∫Øt k·∫øt n·ªëi, lu·ªìng command_handler s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω vi·ªác d·ª´ng bot
                    break # Tho√°t v√≤ng l·∫∑p g·ª≠i log
                
                # N·∫øu context v·∫´n active nh∆∞ng kh√¥ng c√≥ log, ti·∫øp t·ª•c v√≤ng l·∫∑p

            except Exception as e:
                print(f"Error in StreamBotCrawlUrl loop: {e}")
                break # Tho√°t v√≤ng l·∫∑p n·∫øu c√≥ l·ªói kh√¥ng mong mu·ªën

        # ƒê·∫£m b·∫£o lu·ªìng command_handler k·∫øt th√∫c tr∆∞·ªõc khi h√†m StreamBotCrawlUrl tr·∫£ v·ªÅ
        command_thread.join()
        print(f"StreamBotCrawlUrl for bot_id={bot_id if bot_id else 'unknown'} completed.")
    def StreamBotCrawlDetail(self, request_iterator, context):
        for command in request_iterator:
                bot_id = command.bot_id
                cmd_type = command.type
                print(bot_id)
                print(cmd_type)
def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    bot_pb2_grpc.add_BotServiceServicer_to_server(BotServiceServicer(), server)
    server.add_insecure_port('[::]:50051')
    print("üöÄ gRPC server started on port 50051")
    server.start()
    
    try:
        while True:
            time.sleep(86400) # Gi·ªØ server ch·∫°y
    except KeyboardInterrupt:
        print("\nShutting down gRPC server...")
        # Cleanup t·∫•t c·∫£ c√°c bot ƒëang ho·∫°t ƒë·ªông khi server t·∫Øt
        for bot_id, bot_data in active_bots.items():
            if bot_data["scraper"]:
                print(f"Cleaning up bot {bot_id} on server shutdown.")
                bot_data["scraper"].set_stop() # ƒê·∫£m b·∫£o worker thread d·ª´ng
                bot_data["thread"].join(timeout=5) # Ch·ªù worker thread k·∫øt th√∫c
                if bot_data["scraper"].driver: # Ch·ªâ cleanup n·∫øu driver c√≤n t·ªìn t·∫°i
                    bot_data["scraper"].cleanup()
        server.stop(0)
    finally:
        print("gRPC server stopped.")

if __name__ == '__main__':
    serve()